# -*- coding: utf-8 -*-
"""Безрукова_АрабскиеЧисла.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aMPA7VJDRw1CyKY8ckR2tS7dBxXSIEgP
"""

import os
import torch
import torch.nn as nn
from torch.utils.data import (
    Dataset,
    DataLoader,
)
import torchvision.transforms as transforms
import pandas as pd
from skimage import io
import matplotlib as mpl
import matplotlib.pyplot as plt
from tqdm import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class ArabicNumDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.annotations = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, index):
        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 1], self.annotations.iloc[index, 2])
        image = io.imread(img_path)
        y_label = torch.tensor(int(self.annotations.iloc[index, 0]))

        if self.transform:
            image = self.transform(image)

        return (image, y_label)

!unzip "/content/archive_arabic.zip"

import os
import pandas as pd
import cv2
from PIL import Image

list_ = []
for index, folder in enumerate(os.listdir("/content/dataset")):
    print(index, folder)
    for file in os.listdir(os.path.join("/content/dataset", str(folder))):
        basewidth = 32
        img = Image.open(os.path.join("/content/dataset/", str(folder), file))
        wpercent = (basewidth/float(img.size[0]))
        hsize = int((float(img.size[1])*float(wpercent)))
        img = img.resize((basewidth,hsize), Image.ANTIALIAS)
        img = img.convert('1')
        img.save(os.path.join("/content/dataset/", str(folder), file))
        im = cv2.imread(os.path.join("/content/dataset/", str(folder), file))
        print(im.shape)
        list_.extend([[index, folder, file]])

df = pd.DataFrame(list_)
df.to_csv("test1.csv",index=False)

dataset = ArabicNumDataset(
    csv_file="/content/test1.csv",
    root_dir="/content/dataset",
    transform=transforms.ToTensor(),
)

print(len(dataset))

batch_size = 60
num_epochs = 100

train_set, test_set = torch.utils.data.random_split(dataset, [240, 60])
train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)

import matplotlib as mpl
import matplotlib.pyplot as plt
for i, (images, y_label) in enumerate(train_loader):
        print(images.size())
        image=images[0,:,:,:]
        image_s=torch.squeeze(image, 0)
        image_s=torch.squeeze(image_s, 0)
        image_s=image_s.T
        print(image_s.size())
        plt.imshow(image_s.numpy(), cmap="gray")
        break

class FeedforwardNeuralNetModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(FeedforwardNeuralNetModel, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim) 
        self.sigmoid = nn.Sigmoid()
        self.fc2 = nn.Linear(hidden_dim, output_dim)  

    def forward(self, x):
        out = self.fc1(x)
        out = self.sigmoid(out)
        out = self.fc2(out)
        return out

input_dim = 32*32 
hidden_dim = 100 
output_dim = 10 

model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)

learning_rate = 0.1 
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # оптимизатор


criterion = nn.CrossEntropyLoss()

iter = 0
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = images.view(-1, 32*32)
        optimizer.zero_grad()
        outputs = model(images.float())
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        iter += 1
        if iter % 100 == 0: 
            correct = 0
            total = 0
            for images, labels in test_loader:
                images = images.view(-1, 32*32).requires_grad_()
                outputs = model(images.float())
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
            accuracy = 100 * correct / total
            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))